{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3267e651-8411-4062-9d87-7deb9bfe9d5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from parser import parser\n",
    "from model import SaintPlus, NoamOpt\n",
    "from torch.utils.data import DataLoader\n",
    "from data_generator import Riiid_Sequence\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28684528-abab-4adf-8db6-abebd3a516ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c9c54a-1ad0-4be0-89af-4084d6a5d15d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_problems = 9454\n",
    "n_tests = 1537\n",
    "n_categories = 9\n",
    "n_tags = 912\n",
    "\n",
    "num_layers = 2\n",
    "num_heads = 4\n",
    "d_model = 128\n",
    "d_ffn = d_model*4\n",
    "\n",
    "seq_len = 100\n",
    "warmup_steps = 4000\n",
    "dropout = 0.1\n",
    "epochs = 1000\n",
    "patience = 100\n",
    "batch_size = 128\n",
    "\n",
    "fold_n = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9874956-08aa-41f6-89fa-b08e995ad1d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"/opt/ml/input/data/train_group.pkl.zip\", 'rb') as pick:\n",
    "    group = pickle.load(pick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ab38a2-c96f-41e1-9cb7-134d15f9be49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09e1893-9189-4ee6-94eb-63e24d9487fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "kf = KFold(n_splits = fold_n, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f5dc39-5715-4033-ae0d-4fcf8d7504ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_best_auc = [0] * fold_n\n",
    "for i, (train_index, valid_index) in enumerate(kf.split(group.index)):\n",
    "    train_group = group[group.index[train_index]]\n",
    "    val_group = group[group.index[valid_index]]\n",
    "    \n",
    "    train_loader = DataLoader(Riiid_Sequence(train_group, seq_len), batch_size=batch_size, shuffle=True, num_workers=8)\n",
    "    val_loader = DataLoader(Riiid_Sequence(val_group, seq_len), batch_size=batch_size, shuffle=False, num_workers=8)\n",
    "    \n",
    "    loss_fn = nn.BCELoss()\n",
    "    model = SaintPlus(seq_len=seq_len, num_layers=num_layers, d_ffn=d_ffn, d_model=d_model, num_heads=num_heads,\n",
    "                      n_problems=n_problems, n_tests=n_tests, n_categories=n_categories, n_tags=n_tags,\n",
    "                      dropout=dropout)\n",
    "    optimizer = NoamOpt(d_model, 1, 4000 ,optim.Adam(model.parameters(), lr=0))\n",
    "    model.to(device)\n",
    "    loss_fn.to(device)\n",
    "    \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    val_aucs = []\n",
    "    best_auc = 0\n",
    "    count = 0\n",
    "    for e in range(epochs):\n",
    "        print(\"==========Epoch {} Start Training==========\".format(e+1))\n",
    "        model.train()\n",
    "        t_s = time.time()\n",
    "        train_loss = []\n",
    "        for step, data in enumerate(train_loader):\n",
    "            category_sample = data[0].to(device).long()\n",
    "            category_test_sample = data[1].to(device).long()\n",
    "            category_test_problem_sample = data[2].to(device).long()\n",
    "            problem_tag_sample = data[3].to(device).long()\n",
    "            problem_time_sample = data[4].to(device).float()\n",
    "            break_time_sample = data[5].to(device).float()\n",
    "            answer_sample = data[6].to(device).long()\n",
    "            label = data[7].to(device).float()\n",
    "\n",
    "            optimizer.optimizer.zero_grad()\n",
    "\n",
    "            preds = model(category_sample, category_test_sample, category_test_problem_sample, problem_tag_sample, break_time_sample, problem_time_sample, answer_sample)\n",
    "            loss_mask = (answer_sample != 0)\n",
    "            preds_masked = torch.masked_select(preds, loss_mask)\n",
    "            label_masked = torch.masked_select(label, loss_mask)\n",
    "            loss = loss_fn(preds_masked, label_masked)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss.append(loss.item())\n",
    "\n",
    "        train_loss = np.mean(train_loss)\n",
    "        print(\"==========Epoch {} Start Validation==========\".format(e+1))\n",
    "        model.eval()\n",
    "        val_loss = []\n",
    "        val_labels = []\n",
    "        val_preds = []\n",
    "        for step, data in enumerate(val_loader):\n",
    "            category_sample = data[0].to(device).long()\n",
    "            category_test_sample = data[1].to(device).long()\n",
    "            category_test_problem_sample = data[2].to(device).long()\n",
    "            problem_tag_sample = data[3].to(device).long()\n",
    "            problem_time_sample = data[4].to(device).float()\n",
    "            break_time_sample = data[5].to(device).float()\n",
    "            answer_sample = data[6].to(device).long()\n",
    "            label = data[7].to(device).float()\n",
    "\n",
    "            preds = model(category_sample, category_test_sample, category_test_problem_sample, problem_tag_sample, break_time_sample, problem_time_sample, answer_sample)\n",
    "            loss_mask = (answer_sample != 0)\n",
    "            preds_masked = torch.masked_select(preds, loss_mask)\n",
    "            label_masked = torch.masked_select(label, loss_mask)\n",
    "\n",
    "            val_loss.append(loss.item())\n",
    "            val_labels.extend(label_masked.view(-1).data.cpu().numpy())\n",
    "            val_preds.extend(preds_masked.view(-1).data.cpu().numpy())\n",
    "\n",
    "        val_loss = np.mean(val_loss)\n",
    "        val_auc = roc_auc_score(val_labels, val_preds)\n",
    "\n",
    "        if val_auc > best_auc:\n",
    "            print(\"Save model at epoch {}\".format(e+1))\n",
    "            torch.save(model.state_dict(), \"./saint.pt\")\n",
    "            best_auc = val_auc\n",
    "            fold_best_auc[i] = best_auc\n",
    "            count = 0\n",
    "        else:\n",
    "            count += 1\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        val_aucs.append(val_auc)\n",
    "        exec_t = int((time.time() - t_s)/60)\n",
    "        print(\"Train Loss {:.4f}/ Val Loss {:.4f}, Val AUC {:.4f} / Exec time {} min\".format(train_loss, val_loss, val_auc, exec_t))\n",
    "        if count >= patience:\n",
    "            print('Early Stopping!')\n",
    "            break\n",
    "        \n",
    "print(mean(fold_best_auc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bc_torch",
   "language": "python",
   "name": "bc_torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
